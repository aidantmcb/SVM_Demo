{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e08464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from TolColors import tol_cmap # for better visualizations\n",
    "cmap = tol_cmap('rainbow_PuRd')\n",
    "\n",
    "# Some cosmetic updates\n",
    "import matplotlib \n",
    "matplotlib.rcParams.update({'xtick.labelsize':18,\n",
    "                            'ytick.labelsize':18,\n",
    "                            'axes.titlesize':18,\n",
    "                            'axes.labelsize':18,\n",
    "                            'font.size':18,\n",
    "                            'xtick.top':True,\n",
    "                            'xtick.minor.visible':True,\n",
    "                            'ytick.minor.visible':True,\n",
    "                            'xtick.major.size':4,\n",
    "                            'xtick.minor.size':1.5,\n",
    "                            'ytick.major.size':4,\n",
    "                            'ytick.minor.size':1.5,\n",
    "                            'ytick.right':True,\n",
    "                            'xtick.direction':'in',\n",
    "                            'ytick.direction':'in',\n",
    "                            'font.family':'serif',\n",
    "                            'lines.markersize': 10,\n",
    "                            'image.cmap': cmap})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a04abe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### scikit-learn's SVM implementation: SVC ###\n",
    "from sklearn.svm import SVC "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3e4ab7",
   "metadata": {},
   "source": [
    "# Linear SVMs\n",
    "## Create classes of clustered points\n",
    "Data needs to be of form: \\\n",
    "`X`: a variable containing the measurable parameters for each point; has shape (n_samples, n_features) \\\n",
    "`y`: a variable containing the class for each data point (think: the auxillary axis of a scatter plot);\n",
    "    has shape (n_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbfaaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate example dataset ###\n",
    "\n",
    "\n",
    "\n",
    "N_A = #CHOOSE SOME NUMBER OF POINTS; I DID 10\n",
    "N_B = N_A #TRY CHANGING THIS TO A SEPARATE VALUE\n",
    "\n",
    "\n",
    "\n",
    "mu_A = np.array([1.0, 1.0])\n",
    "mu_B = np.array([2.0, 2.0])\n",
    "## X1 and X2 means for our two distributions\n",
    "\n",
    "cov_A = np.array([[1, -0.5], \n",
    "                 [-0.5, 1]]) \n",
    "cov_B = cov_A \n",
    "## covariance matrices for random sampled gaussians\n",
    "\n",
    "X_A = np.random.multivariate_normal(mu_A, cov_A, N_A)\n",
    "X_B = np.random.multivariate_normal(mu_B, cov_B, N_B)\n",
    "## Generates N two-dimensional random samples centered at [1,1] and [2,2] respectively\n",
    "\n",
    "X = np.vstack([X_A, X_B])\n",
    "## X has shape (N_samples, N_features), where N_samples = N_A + N_B \n",
    "\n",
    "y = np.hstack([np.zeros(N_A), np.ones(N_B)])\n",
    "## y = 0 corresponds to the X1 distribution\n",
    "## y = 1 corresponds to the X2 distribution\n",
    "\n",
    "print('X shape:', X.shape)\n",
    "print('y shape:', y.shape)\n",
    "\n",
    "\n",
    "## try printing X and y to make sure they make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b93116",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the input dataset, using data class as the color ### \n",
    "fig, ax = plt.subplots(figsize = (8,6))\n",
    "\n",
    "## Every X variable has shape (N_points, 2), so access as X[:, column] for column = {0, 1}\n",
    "## Can use X1 -> X[:,0] and X2 -> [:,1] with y as the color (aux) axis\n",
    "## OR you can separately plot X_A and X_B, matplotlib will take care of the colors for you\n",
    "\n",
    "## EG: ax.scatter(X1, X2, c = y)\n",
    "\n",
    "\n",
    "\n",
    "#SCATTER PLOT OF DATA POINTS HERE\n",
    "## you'll want to copy-paste this plot statement a few times later on\n",
    "\n",
    "\n",
    "ax.set_xlabel('X1')\n",
    "ax.set_ylabel('X2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e386c7b",
   "metadata": {},
   "source": [
    "## Fit SVM:\n",
    "We'll teach `sklearn.svm`'s SVC (C-Support Vector Classification) to classify our data. More information about scikit-learn's SVM implementations can be found [here](https://scikit-learn.org/stable/modules/svm.html#svm-classification).\n",
    "\n",
    "The `SVC` object can be initialized by name, and then fit to the data using its built-in `fit(X,y)` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e57891",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel = 'linear') ## creates a new linear SVC model \n",
    "#FIT YOUR MODEL TO YOUR X AND y DATA HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1c33cf",
   "metadata": {},
   "source": [
    "Once fit, we can access a few useful model attributes\n",
    "+ `svm.support_vectors_`: gives the 'support vectors', the nearest data that were used to define the hyperplane\n",
    "+ `svm.support_`: gives indices of the suppport vectors\n",
    "+ `svm.coef_`: gives the weights of the classifier - for a linear classifier, corresponds to weights of X1 and X2\n",
    "+ `svm.intercept_`: gives the unweighted intercept of the hyperplane "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f904e0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try printing off the model's support vectors - what do these correspond to?\n",
    "support_vecs = #GET SUPPORT VECTORS FROM MODEL\n",
    "print(support_vecs)\n",
    "## these should have a similar shape to X for plotting purposes!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d1f9bc",
   "metadata": {},
   "source": [
    "We can use the weights and intercepts from the model to calculate the fitted hyperplane to the data. This calculation is a little obscure, so don't worry about it too much!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7d9aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate the \"hyperplane\" between the two classes of data ###\n",
    "w = model.coef_[0]\n",
    "m = - w[0] / w[1] ## slope of the line derived from the weights of the classifier\n",
    "b = - model.intercept_[0] / w[1] ## y intercept of hyperplane, weighted \n",
    "\n",
    "xx = np.linspace(0.8 * np.min(X[:,0]), 1.2 * np.max(X[:,0]))\n",
    "yy = m * xx + b ## this should be the line that best separates the two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32ec85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the hyperplane separating these two classes ###\n",
    "fig, ax = plt.subplots(figsize = (8,6))\n",
    "\n",
    "\n",
    "#SCATTER PLOT OF DATA POINTS HERE\n",
    "\n",
    "\n",
    "## Circle the support vectors; REQUIRES THAT YOU'VE ALREADY DEFINED support_vecs\n",
    "ax.scatter(support_vecs[:,0], support_vecs[:,1], \n",
    "           s = 400, facecolors = 'none', edgecolors = 'k') #cosmetics\n",
    "\n",
    "\n",
    "## Plot the hyperplane separating the two classes\n",
    "ax.plot(xx, yy)\n",
    "ax.set_xlabel('X1')\n",
    "ax.set_ylabel('X2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc5ae05",
   "metadata": {},
   "source": [
    "What do you notice about the fit?\n",
    "\n",
    "## SVM Predictions\n",
    "Now, we can use `SVC.predict(X)` to predict the labels for an unclassified input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe2ae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate some gaussian unlabeled input data, centered on [1.5, 1.5] ###\n",
    "N = #CHOOSE NUMBER OF UNKNOWN DATA POINTS; I DID 500\n",
    "\n",
    "\n",
    "\n",
    "X_ = np.random.multivariate_normal([1.5,1.5], np.eye(2), N)\n",
    "\n",
    "\n",
    "\n",
    "y_ = #GET MODEL PREDICTIONS FOR X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fde7638",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (8,6))\n",
    "\n",
    "\n",
    "#SCATTER PLOT OF YOUR NEW X_ AND y_ DATA POINTS HERE\n",
    "\n",
    "\n",
    "ax.plot(xx, yy)\n",
    "ax.set_xlabel('X1')\n",
    "ax.set_ylabel('X2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a7b5a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163f644a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f18c307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95bbbb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71ed796a",
   "metadata": {},
   "source": [
    "# SVMs with nonlinear data\n",
    "## Create non-linearly-separable datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30819ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate X and y arrays for a more complicated dataset ###\n",
    "\n",
    "N_A = #CHOOSE SOME NUMBER OF SAMPLES; I DID 100\n",
    "N_B = N_A #TRY CHANGING THIS TO A NEW NUMBER\n",
    "\n",
    "\n",
    "\n",
    "cov = np.array([[1,0],[0,1]]) ## spherical covariance\n",
    "\n",
    "X_A = np.random.multivariate_normal([0,0], cov, N_A)\n",
    "# Generates a two-dimensional, homoscedastic gaussian sample\n",
    "\n",
    "X_B = np.random.multivariate_normal([0,0], cov, N_B) \n",
    "r = 2\n",
    "mag = np.sqrt(X_B[:, 0]**2 + X_B[:, 1]**2)\n",
    "cos_sin = np.divide(X_B, np.vstack([mag, mag]).T) # calculates cos and sin of random positions\n",
    "X_B = X_B + r * cos_sin\n",
    "# Generates a random disk sample by transforming a two-dimensional gaussian sample to\n",
    "# the parametrized circle (x + r * cos(theta), y + r * sin(theta))\n",
    "\n",
    "X = np.vstack([X_A, X_B])\n",
    "# X has shape (2 * N_samples, N_features)\n",
    "\n",
    "y = np.hstack([np.zeros(N_A), np.ones(N_B)])\n",
    "# Generate labels for each population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd637ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try printing the data or using array.shape to understand their dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8086d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the datapoints ###\n",
    "fig, ax = plt.subplots(figsize = (8,8))\n",
    "\n",
    "\n",
    "## you should be able to plot these the exact same way as the earlier X and y\n",
    "#SCATTER PLOT OF DATA POINTS HERE\n",
    "\n",
    "\n",
    "ax.set_xlabel('X1')\n",
    "ax.set_ylabel('X2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120454e7",
   "metadata": {},
   "source": [
    "These datapoints are obviously not linearly seaparable! Let's see what SVM makes of this with different approaches...\n",
    "\n",
    "## Kernels:\n",
    "SVM classifiers can use other \"kernels\" besides linear hyperplanes to fit data of different shapes\n",
    "+ Linear kernel: $\\langle x, x \\prime \\rangle$ - the most straightforward kernel; use with `kernel = 'linear'`\n",
    "+ Gaussian (or Radial Basis Function) kernel: $\\exp(-\\gamma \\vert \\vert x_i - x_i \\prime ||^2)$ for some $\\gamma$; use with `kernel = 'rbf'`\n",
    "+ Polynomial: $(\\gamma \\langle x, x\\prime \\rangle + r)^2$ for some $\\gamma, d$; use with `kernel = 'poly'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df73525c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel = 'linear') ## TRY SWITCHING TO A BETTER KERNEL - E.G. kernel = 'rbf'\n",
    "\n",
    "\n",
    "#FIT YOUR NEW MODEL THE SAME WAY AS BEFORE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70d401c",
   "metadata": {},
   "source": [
    "It's now a lot harder to parametrize this boundary now that it's nonlinear, so we instead fit our model to a grid in the (X1, X2) plane and then calculate the boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaaddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the classifier boundaries from model prediction ###\n",
    "xx1, xx2 = np.meshgrid(np.linspace(-4,4,1000), \n",
    "                    np.linspace(-4,4,1000))\n",
    "\n",
    "xx = np.vstack([xx1.ravel(), xx2.ravel()]).T ## gets a grid of points with the same shape as X\n",
    "yy = model.predict(xx)\n",
    "yy = yy.reshape(xx1.shape) ## for contour plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3bb0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the datapoints ###\n",
    "fig, ax = plt.subplots(figsize = (8,8))\n",
    "\n",
    "\n",
    "\n",
    "#SCATTER PLOT OF DATA POINTS HERE\n",
    "\n",
    "\n",
    "ax.contour(xx1, xx2, yy)\n",
    "ax.set_xlabel('X1')\n",
    "ax.set_ylabel('X2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce81df4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to, you can try generating a new random sample and use the model.predict() to classify it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b900a15",
   "metadata": {},
   "source": [
    "# Outside Resources\n",
    "+ For SVM classification with larger numbers of classes and kernel types, check out [the graphic interface provided by `libsvm`](https://www.csie.ntu.edu.tw/~cjlin/libsvm/).\n",
    "\n",
    "+ The libsvm team also wrote a very good [beginner's guide to parametric svm](https://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf).\n",
    "\n",
    "+ The [scikit-learn SVM overview](https://scikit-learn.org/stable/modules/svm.html#svm-classification) has a lot of information about how to use their various models, as well as the mathematical formulation behind them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python397jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
